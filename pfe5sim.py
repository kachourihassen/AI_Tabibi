# -*- coding: utf-8 -*-
"""PFE5SIM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HO2TwGAUtClIoJIyZArn7JXkdCjRPXSG
"""

import pandas as pd
import numpy as np
import io
from sklearn import preprocessing
!pip install Unidecode
!pip install transformers
!pip install langdetect
!pip install tensorflow==2.7.0

import pandas as pd 
import numpy as np

from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

import tensorflow as tf 
from tensorflow.keras.layers import Dense, Input
from tensorflow.keras.optimizers import Adam 
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.models import Model
import matplotlib.pyplot as plt

import transformers
from transformers import TFAutoModel, AutoTokenizer
from tqdm.notebook import tqdm
from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors

from sklearn.model_selection import KFold
from tokenizers import BertWordPieceTokenizer
 
import re
import os

import nltk
from nltk.corpus import stopwords
nltk.download('stopwords')

import fileinput
import sys

import warnings
import unidecode

import string
from textblob import TextBlob 

from langdetect import detect
import seaborn as sns

from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn import model_selection, naive_bayes, svm
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.pipeline import make_pipeline
from sklearn.metrics import confusion_matrix,accuracy_score, classification_report
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC

from tensorflow.keras.layers import LSTM, GRU, Dense, Embedding, Dropout

dataset = 'Data.xlsx'
#dataset = 'Patient_Data.xlsx'
df=pd.read_excel(dataset)

df.head()

df["Speciality"].value_counts()

def remove_emoji(string):
    emoji_pattern = re.compile("["
                               u"\U0001F600-\U0001F64F"  # emoticons
                               u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                               u"\U0001F680-\U0001F6FF"  # transport & map symbols
                               u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                               u"\U00002500-\U00002BEF"  # chinese char
                               u"\U00002702-\U000027B0"
                               u"\U00002702-\U000027B0"
                               u"\U000024C2-\U0001F251"
                               u"\U0001f926-\U0001f937"
                               u"\U00010000-\U0010ffff"
                               u"\u2640-\u2642"
                               u"\u2600-\u2B55"
                               u"\u200d"
                               u"\u23cf"
                               u"\u23e9"
                               u"\u231a"
                               u"\ufe0f"  # dingbats
                               u"\u3030"
                               "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', string)

df['Description'] = df['Description'].apply(lambda x:remove_emoji(x))
df['Speciality'] = df['Speciality'].apply(lambda x:remove_emoji(x))

import re #fournit des opérations de correspondance d'expressions régulière
import string
#from cleantext import clean
def clean_text(text):
    
    text = str(text).lower()
    text = re.sub('\[.*?\]', '', text)
    text = re.sub('https?://\S+|www\.\S+', '', text)
    text = re.sub('<.*?>+', '', text)
    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
    text = re.sub('\n', '', text)
    text = re.sub('\w*\d\w*', '', text)
    text=  re.sub('\d* replies', '',text)
    text = re.sub('\d* likes', '', text)
    text = re.sub('\d* reply', '', text)
    text = re.sub('\d* like', '', text)
    text = text.replace("Report / Delete", "")
    
    return text

df['Description'] = df['Description'].apply(lambda x:clean_text(x))
df['Speciality'] = df['Speciality'].apply(lambda x:clean_text(x))

#df.Description = df.Description.apply(str)
df

!pip install stop-words

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

stop_words = stopwords.words('english')
df['Description'] = df['Description'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))

df

df.Description = df.Description.apply(str)

from torch.utils.data import random_split


# Split into training and validation sets
train_size = int(0.1 * len(df))
val_size = len(df) - train_size

train, test= random_split(df, [train_size, val_size])

f'There are {train_size} samples for training, and {val_size} samples for validation testing'

x = df.Description.values.tolist()
y = df.Speciality.values.tolist()

from sklearn.feature_extraction.text import CountVectorizer
vectorizer = CountVectorizer()
data1 = vectorizer.fit_transform(x)

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(data1, y, test_size=0.2, random_state=42,stratify=y)

#@title Naive Bayes Classifier

# Commented out IPython magic to ensure Python compatibility.
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import MultinomialNB

mnb = MultinomialNB() 
# %time mnb.fit(x_train, y_train)

y_pred_train = mnb.predict(x_train)
y_pred_test = mnb.predict(x_test)
print("\nTraining Accuracy score:",accuracy_score(y_train, y_pred_train))
print("Testing Accuracy score:",accuracy_score(y_test, y_pred_test))

from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred_test))

cm = confusion_matrix(y_test, y_pred_test)
# print('Confusion matrix\n', cm)

cm_matrixNB = pd.DataFrame(data=cm, columns=['Actual Anxiety Disorders', 'Actual Depression', 'Actual Hip_Replacement', 'Actual Irritable-bowel-syndrome','Actual Knee_Problems','Actual Menopause','Actual Polymyalgia_Rheumatica_and_GCA'], 
                        index=['Predict Anxiety Disorders', 'Predict Depression', 'Predict Hip_Replacement', 'Predict Irritable-bowel-syndrome','Predict Knee_Problems','Predict Menopause','Predict Polymyalgia_Rheumatica_and_GCA'])
sns.heatmap(cm_matrixNB, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

#@title Logistic Regression Classifier

from sklearn.linear_model import LogisticRegression

# Commented out IPython magic to ensure Python compatibility.
lr = LogisticRegression(random_state=42)
# %time lr.fit(x_train, y_train)

y_pred_train = lr.predict(x_train)
y_pred_test = lr.predict(x_test)
print("\nTraining Accuracy score:",accuracy_score(y_train, y_pred_train))
print("Testing Accuracy score:",accuracy_score(y_test, y_pred_test))

print(classification_report(y_test, y_pred_test))

cm = confusion_matrix(y_test, y_pred_test)
# print('Confusion matrix\n', cm)

cm_matrixNB = pd.DataFrame(data=cm, columns=['Actual Anxiety Disorders', 'Actual Depression', 'Actual Hip_Replacement','Actual Knee_Problems','Actual Menopause','Actual Polymyalgia_Rheumatica_and_GCA'], 
                        index=['Predict Anxiety Disorders', 'Predict Depression', 'Predict Hip_Replacement','Predict Knee_Problems','Predict Menopause','Predict Polymyalgia_Rheumatica_and_GCA'])
sns.heatmap(cm_matrixNB, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

#@title Support Vector Machines

from sklearn.svm import LinearSVC

# Commented out IPython magic to ensure Python compatibility.
svc =  LinearSVC(class_weight='balanced') 
# %time svc.fit(x_train, y_train)

y_pred_train = svc.predict(x_train)
y_pred_test = svc.predict(x_test)
print("\nTraining Accuracy score:",accuracy_score(y_train, y_pred_train))
print("Testing Accuracy score:",accuracy_score(y_test, y_pred_test))

print(classification_report(y_test, y_pred_test))

cm = confusion_matrix(y_test, y_pred_test)
# print('Confusion matrix\n', cm)

cm_matrixNB = pd.DataFrame(data=cm, columns=['Actual Anxiety Disorders', 'Actual Depression', 'Actual Hip_Replacement', 'Actual Knee_Problems','Actual Menopause','Actual Polymyalgia_Rheumatica_and_GCA'], 
                        index=['Predict Anxiety Disorders', 'Predict Depression', 'Predict Hip_Replacement', 'Predict Knee_Problems','Predict Menopause','Predict Polymyalgia_Rheumatica_and_GCA'])
sns.heatmap(cm_matrixNB, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

"""Decision Tree Classifier"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=42)
# %time dt.fit(x_train, y_train)

y_pred_train = dt.predict(x_train)
y_pred_test = dt.predict(x_test)
print("\nTraining Accuracy score:",accuracy_score(y_train, y_pred_train))
print("Testing Accuracy score:",accuracy_score(y_test, y_pred_test))

print(classification_report(y_test, y_pred_test))

cm = confusion_matrix(y_test, y_pred_test)
# print('Confusion matrix\n', cm)

cm_matrixNB = pd.DataFrame(data=cm, columns=['Actual Anxiety Disorders', 'Actual Depression', 'Actual Hip_Replacement', 'Actual Irritable-bowel-syndrome','Actual Knee_Problems','Actual Menopause','Actual Polymyalgia_Rheumatica_and_GCA'], 
                        index=['Predict Anxiety Disorders', 'Predict Depression', 'Predict Hip_Replacement', 'Predict Irritable-bowel-syndrome','Predict Knee_Problems','Predict Menopause','Predict Polymyalgia_Rheumatica_and_GCA'])
sns.heatmap(cm_matrixNB, annot=True, fmt='d', cmap='YlGnBu')
plt.show()

from sklearn.ensemble import VotingClassifier

classifiers = [('Decision Tree', dt),
               ('Logistic Regression', lr),
                ('Naive Bayes', mnb)
              ]
vc = VotingClassifier(estimators=classifiers)
# Fit 'vc' to the traing set and predict test set labels
vc.fit(x_train, y_train)
y_pred_train=vc.predict(x_train)
y_pred_test = vc.predict(x_test)
print("Training Accuracy score:",accuracy_score(y_train, y_pred_train))
print("Testing Accuracy score:",accuracy_score(y_test, y_pred_test))

import pickle
pickle.dump(mnb,open('my_classifier.pickle', 'wb'))

model = pickle.load(open('my_classifier.pickle', 'rb'))